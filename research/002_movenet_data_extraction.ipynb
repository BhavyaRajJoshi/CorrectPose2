{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/richcriticism/Documents/Documents/Bhavya_code/CorrectPose2/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/richcriticism/Documents/Documents/Bhavya_code/CorrectPose2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q imageio\n",
    "!pip3 install -q opencv-python\n",
    "!pip3 install -q git+https://github.com/tensorflow/docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
      "fatal: destination path 'examples' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O movenet_thunder.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
    "!git clone https://github.com/tensorflow/examples.git\n",
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "\n",
    "movenet = Movenet('movenet_thunder')\n",
    "\n",
    "# Define function to run pose estimation using MoveNet Thunder.\n",
    "# You'll apply MoveNet's cropping algorithm and run inference multiple times on\n",
    "# the input image to improve pose estimation accuracy.\n",
    "def detect(input_tensor, inference_count=3):\n",
    "  \"\"\"Runs detection on an input image.\n",
    "\n",
    "  Args:\n",
    "    input_tensor: A [height, width, 3] Tensor of type tf.float32.\n",
    "      Note that height and width can be anything since the image will be\n",
    "      immediately resized according to the needs of the model within this\n",
    "      function.\n",
    "    inference_count: Number of times the model should run repeatly on the\n",
    "      same input image to improve detection accuracy.\n",
    "\n",
    "  Returns:\n",
    "    A Person entity detected by the MoveNet.SinglePose.\n",
    "  \"\"\"\n",
    "  image_height, image_width, channel = input_tensor.shape\n",
    "\n",
    "  # Detect pose using the full input image\n",
    "  movenet.detect(input_tensor.numpy(), reset_crop_region=True)\n",
    "\n",
    "  # Repeatedly using previous detection result to identify the region of\n",
    "  # interest and only croping that region to improve detection accuracy\n",
    "  for _ in range(inference_count - 1):\n",
    "    person = movenet.detect(input_tensor.numpy(), \n",
    "                            reset_crop_region=False)\n",
    "\n",
    "  return person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "#from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "#import imageio\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow_hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow_hub) (3.20.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow_hub) (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.43.0)\n",
      "Requirement already satisfied: rich in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.17.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/richcriticism/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction_on_image(\n",
    "    image, person, crop_region=None, close_figure=True,\n",
    "    keep_input_size=False):\n",
    "  \"\"\"Draws the keypoint predictions on image.\n",
    " \n",
    "  Args:\n",
    "    image: An numpy array with shape [height, width, channel] representing the\n",
    "      pixel values of the input image.\n",
    "    person: A person entity returned from the MoveNet.SinglePose model.\n",
    "    close_figure: Whether to close the plt figure after the function returns.\n",
    "    keep_input_size: Whether to keep the size of the input image.\n",
    " \n",
    "  Returns:\n",
    "    An numpy array with shape [out_height, out_width, channel] representing the\n",
    "    image overlaid with keypoint predictions.\n",
    "  \"\"\"\n",
    "  # Draw the detection result on top of the image.\n",
    "  image_np = utils.visualize(image, [person])\n",
    "  \n",
    "  # Plot the image with detection results.\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  im = ax.imshow(image_np)\n",
    " \n",
    "  if close_figure:\n",
    "    plt.close(fig)\n",
    " \n",
    "  if not keep_input_size:\n",
    "    image_np = utils.keep_aspect_ratio_resizer(image_np, (512, 512))\n",
    "\n",
    "  return image_np\n",
    "\n",
    "\n",
    "class MoveNetPreprocessor(object):\n",
    "  \"\"\"Helper class to preprocess pose sample images for classification.\"\"\"\n",
    " \n",
    "  def __init__(self,\n",
    "               images_in_folder,\n",
    "               images_out_folder,\n",
    "               csvs_out_path):\n",
    "    \"\"\"Creates a preprocessor to detection pose from images and save as CSV.\n",
    "\n",
    "    Args:\n",
    "      images_in_folder: Path to the folder with the input images. It should\n",
    "        follow this structure:\n",
    "        yoga_poses\n",
    "        |__ downdog\n",
    "            |______ 00000128.jpg\n",
    "            |______ 00000181.bmp\n",
    "            |______ ...\n",
    "        |__ goddess\n",
    "            |______ 00000243.jpg\n",
    "            |______ 00000306.jpg\n",
    "            |______ ...\n",
    "        ...\n",
    "      images_out_folder: Path to write the images overlay with detected\n",
    "        landmarks. These images are useful when you need to debug accuracy\n",
    "        issues.\n",
    "      csvs_out_path: Path to write the CSV containing the detected landmark\n",
    "        coordinates and label of each image that can be used to train a pose\n",
    "        classification model.\n",
    "    \"\"\"\n",
    "    self._images_in_folder = images_in_folder\n",
    "    self._images_out_folder = images_out_folder\n",
    "    self._csvs_out_path = csvs_out_path\n",
    "    self._messages = []\n",
    "\n",
    "    # Create a temp dir to store the pose CSVs per class\n",
    "    self._csvs_out_folder_per_class = tempfile.mkdtemp()\n",
    " \n",
    "    # Get list of pose classes and print image statistics\n",
    "    self._pose_class_names = sorted(\n",
    "        [n for n in os.listdir(self._images_in_folder) if not n.startswith('.')]\n",
    "        )\n",
    "    \n",
    "  def process(self, per_pose_class_limit=None, detection_threshold=0.1):\n",
    "    \"\"\"Preprocesses images in the given folder.\n",
    "    Args:\n",
    "      per_pose_class_limit: Number of images to load. As preprocessing usually\n",
    "        takes time, this parameter can be specified to make the reduce of the\n",
    "        dataset for testing.\n",
    "      detection_threshold: Only keep images with all landmark confidence score\n",
    "        above this threshold.\n",
    "    \"\"\"\n",
    "    # Loop through the classes and preprocess its images\n",
    "    for pose_class_name in self._pose_class_names:\n",
    "      print('Preprocessing', pose_class_name, file=sys.stderr)\n",
    "\n",
    "      # Paths for the pose class.\n",
    "      images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
    "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder_per_class,pose_class_name + '.csv')\n",
    "      if not os.path.exists(images_out_folder):\n",
    "        os.makedirs(images_out_folder)\n",
    " \n",
    "      # Detect landmarks in each image and write it to a CSV file\n",
    "\n",
    "      with open(csv_out_path, 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, \n",
    "                                    delimiter=',', \n",
    "                                    quoting=csv.QUOTE_MINIMAL)\n",
    "        # Get list of images\n",
    "        image_names = sorted(\n",
    "            [n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "        if per_pose_class_limit is not None:\n",
    "          image_names = image_names[:per_pose_class_limit]\n",
    "\n",
    "        valid_image_count = 0\n",
    " \n",
    "        # Detect pose landmarks from each image\n",
    "        for image_name in tqdm.tqdm(image_names):\n",
    "          image_path = os.path.join(images_in_folder, image_name)\n",
    "\n",
    "          try:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "          except:\n",
    "            self._messages.append('Skipped ' + image_path + '. Invalid image.')\n",
    "            continue\n",
    "          else:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "            image_height, image_width, channel = image.shape\n",
    "\n",
    "\n",
    "          # Skip images that isn't RGB because Movenet requires RGB images\n",
    "          if channel != 3:\n",
    "            self._messages.append('Skipped ' + image_path +\n",
    "                                  '. Image isn\\'t in RGB format.')\n",
    "            continue\n",
    "          person = detect(image)\n",
    "          \n",
    "          # Save landmarks if all landmarks were detected\n",
    "          min_landmark_score = min(\n",
    "              [keypoint.score for keypoint in person.keypoints])\n",
    "          should_keep_image = min_landmark_score >= detection_threshold\n",
    "          if not should_keep_image:\n",
    "            self._messages.append('Skipped ' + image_path +\n",
    "                                  '. No pose was confidentlly detected.')\n",
    "            continue\n",
    "\n",
    "          valid_image_count += 1\n",
    "\n",
    "          # Draw the prediction result on top of the image for debugging later\n",
    "          output_overlay = draw_prediction_on_image(\n",
    "              image.numpy().astype(np.uint8), person, \n",
    "              close_figure=True, keep_input_size=True)\n",
    "\n",
    "\n",
    "          # Write detection result into an image file\n",
    "          output_frame = cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR)\n",
    "          cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
    "        \n",
    "          # Get landmarks and scale it to the same size as the input image\n",
    "          pose_landmarks = np.array(\n",
    "              [[keypoint.coordinate.x, keypoint.coordinate.y, keypoint.score]\n",
    "                for keypoint in person.keypoints],\n",
    "              dtype=np.float32)\n",
    "\n",
    "          # Write the landmark coordinates to its per-class CSV file\n",
    "          coordinates = pose_landmarks.flatten().astype(np.str_).tolist()\n",
    "          csv_out_writer.writerow([image_name] + coordinates)\n",
    "\n",
    "        if not valid_image_count:\n",
    "          raise RuntimeError(\n",
    "              'No valid images found for the \"{}\" class.'\n",
    "              .format(pose_class_name))\n",
    "      \n",
    "    # Print the error message collected during preprocessing.\n",
    "    print('\\n'.join(self._messages))\n",
    "\n",
    "    # Combine all per-class CSVs into a single output file\n",
    "    all_landmarks_df = self._all_landmarks_as_dataframe()\n",
    "    all_landmarks_df.to_csv(self._csvs_out_path, index=False)\n",
    "\n",
    "  def class_names(self):\n",
    "    \"\"\"List of classes found in the training dataset.\"\"\"\n",
    "    return self._pose_class_names\n",
    "  \n",
    "  def _all_landmarks_as_dataframe(self):\n",
    "    \"\"\"Merge all per-class CSVs into a single dataframe.\"\"\"\n",
    "    total_df = None\n",
    "    for class_index, class_name in enumerate(self._pose_class_names):\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder_per_class,\n",
    "                                  class_name + '.csv')\n",
    "      per_class_df = pd.read_csv(csv_out_path, header=None)\n",
    "      \n",
    "      # Add the labels\n",
    "      per_class_df['class_no'] = [class_index]*len(per_class_df)\n",
    "      per_class_df['class_name'] = [class_name]*len(per_class_df)\n",
    "\n",
    "      # Append the folder name to the filename column (first column)\n",
    "      per_class_df[per_class_df.columns[0]] = (os.path.join(class_name, '') \n",
    "        + per_class_df[per_class_df.columns[0]].astype(str))\n",
    "\n",
    "      if total_df is None:\n",
    "        # For the first class, assign its data to the total dataframe\n",
    "        total_df = per_class_df\n",
    "      else:\n",
    "        # Concatenate each class's data into the total dataframe\n",
    "        total_df = pd.concat([total_df, per_class_df], axis=0)\n",
    " \n",
    "    list_name = [[bodypart.name + '_x', bodypart.name + '_y', \n",
    "                  bodypart.name + '_score'] for bodypart in BodyPart] \n",
    "    header_name = []\n",
    "    for columns_name in list_name:\n",
    "      header_name += columns_name\n",
    "    header_name = ['file_name'] + header_name\n",
    "    header_map = {total_df.columns[i]: header_name[i] \n",
    "                  for i in range(len(header_name))}\n",
    " \n",
    "    total_df.rename(header_map, axis=1, inplace=True)\n",
    "\n",
    "    return total_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m csvs_out_train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m MoveNetPreprocessor(\n\u001b[1;32m      7\u001b[0m     images_in_folder\u001b[38;5;241m=\u001b[39mimages_in_train_folder,\n\u001b[1;32m      8\u001b[0m     images_out_folder\u001b[38;5;241m=\u001b[39mimages_out_train_folder,\n\u001b[1;32m      9\u001b[0m     csvs_out_path\u001b[38;5;241m=\u001b[39mcsvs_out_train_path,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mper_pose_class_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 175\u001b[0m, in \u001b[0;36mMoveNetPreprocessor.process\u001b[0;34m(self, per_pose_class_limit, detection_threshold)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages))\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Combine all per-class CSVs into a single output file\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m all_landmarks_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_all_landmarks_as_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m all_landmarks_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_csvs_out_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 211\u001b[0m, in \u001b[0;36mMoveNetPreprocessor._all_landmarks_as_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m   header_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m columns_name\n\u001b[1;32m    210\u001b[0m header_name \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m header_name\n\u001b[0;32m--> 211\u001b[0m header_map \u001b[38;5;241m=\u001b[39m {\u001b[43mtotal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m[i]: header_name[i] \n\u001b[1;32m    212\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(header_name))}\n\u001b[1;32m    214\u001b[0m total_df\u001b[38;5;241m.\u001b[39mrename(header_map, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_df\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "IMAGES_ROOT = 'artifacts'\n",
    "images_in_train_folder = os.path.join(IMAGES_ROOT, 'train')\n",
    "images_out_train_folder = 'poses_images_out_train'\n",
    "csvs_out_train_path = 'train_data.csv'\n",
    "\n",
    "preprocessor = MoveNetPreprocessor(\n",
    "    images_in_folder=images_in_train_folder,\n",
    "    images_out_folder=images_out_train_folder,\n",
    "    csvs_out_path=csvs_out_train_path,\n",
    ")\n",
    "\n",
    "preprocessor.process(per_pose_class_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
